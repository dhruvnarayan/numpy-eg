# Numpy Examples

% Import Library
import numpy as np

% Instantiate
np.array([1,2,3,4,5]) - List of int,strings,floats,other lists

% Read from csv
test_2 = np.genfromtxt('test_2.csv',delimiter=',') - delimiter can be tabs, colons

% Square rooting each value in numpy array
a = np.array(list)
np.sqrt(a)

% Addition,subtraction of each element is possible easily
a = np.array(list)
b = a + 2
% b is a numpy array

% Numpy arrays can be added,mul,div,sub, other operations with each other
test_1 = np.array([92, 94, 88, 91, 87])
test_2 = np.array([79, 100, 86, 93, 91])
test_3 = np.array([87, 85, 72, 90, 92])
test_3_fixed = test_3 + 2
total_grade = test_1 + test_2 + test_3_fixed
final_grade = total_grade/3

% 2-D array
np.array([[92, 94, 88, 91, 87], 
          [79, 100, 86, 93, 91],
          [87, 85, 72, 90, 92]])
		  
coin_toss = np.array([1,0,0,1,0])
coin_toss_again = np.array([coin_toss,
                           [0,0,1,1,1]])

% Indexing and slicing arrays same as lists

% 2-D arrays
a[2,1] - selecting element from third row and second column since 0 indexing
a[:,0] - select the first column
a[1,:] - select the second row
a[0,0:3] - first three column of the first row

%Logical operations with arrays
a = np.array([10, 2, 2, 4, 5, 3, 9, 8, 9, 7])
a[a > 5] - array([10, 9, 8, 9, 7])
a[(a > 5) | (a < 2)] - array([10, 9, 8, 9, 7])


% Statistics with Numpy


% Mean
np.mean(dataset)
millennials = np.mean(class_year >= 2005) - prints percentage of people attending high school after 2004. True values/Total values
%2-D Arrays
allergy_trials = np.array([[6, 1, 3, 8, 2], 
                           [2, 6, 3, 9, 8], 
                           [5, 2, 6, 9, 9]])
total_mean = np.mean(allergy_trials) - single value, overall mean of dataset
trial_mean = np.mean(allergy_trials, axis = 1) - mean of individual rows
patient_mean = np.mean(allergy_trials, axis = 0) - mean of individual columns

%Sorting
sorted_array = np.sort(array) - Identifies outliers

%Median
median_value = np.median(dataset)
%Median unaffected by outliers mostly, better than mean in context of skewed sets

%Percentile
np.percentile(dataset,n - percentile)
25th percentile - first quartile
50th percentile - median
75th percentile - third quartile

%The five number summary consists of the minimum, above three and the maximum value of dataset
%The difference between the first and third quartile is called the interquartile range. 50% of the dataset will lie within the interquartile range. 
%The interquartile range gives us an idea of how spread out our data is.

% Standard Deviation
% Just like interquartile range, std tells us about the spread of data unlike mean and median which focus on the center
np.std(dataset)


% Basic stats with Matplotlib and Numpy


% Histograms- refer matplotlib - used to study distributions, outliers, frequency of samples
% Histogram distributions can be- 
% Unimodal - single peak - further classified as -
			 %Symmetric/Normal - regular distribution both towards left and right/ Also called normal distribution! - represented by mean and std
			 %Skew-Left - tail towards the left, most data towards the right
			 %Skew-Right - opposite
% Multimodal - multiple peaks
% Bimodal - two peaks - generally occurs when comparing two distinct populations
% Uniform - no outright peaks


%Generating normal distribution
dataset = np.random.normal(mean,std,size)
plt.hist(dataset)

% std and histograms
68% of our samples will fall between +/- 1 standard deviation of the mean
95% of our samples will fall between +/- 2 standard deviations of the mean
99.7% of our samples will fall between +/- 3 standard deviations of the mean

%Binomial Distribution
The binomial distribution is important because it allows us to know how likely a certain outcome is, 
even when it's not the expected one.
dataset= np.random.binomial(N,P,size) - N is number of samples, P is probability of success, size is number of experiments

% Binomial Distributions and Probability
a = np.random.binomial(10, 0.30, size=10000)
np.mean(a == 4)

emails = np.random.binomial(500, 0.05, size=10000)
no_emails = np.mean(emails == 0)
b_test_emails = np.mean(emails>=40)


% Final Program - Important
import numpy as np
from matplotlib import pyplot as plt

sunflowers = np.genfromtxt('sunflower_heights.csv',
                           delimiter=',')

# Calculate mean and std of sunflowers here:
sunflowers_mean = np.mean(sunflowers)
sunflowers_std = np.std(sunflowers)

# Calculate sunflowers_normal here:
sunflowers_normal = np.random.normal(sunflowers_mean,sunflowers_std,5000) - Normalized dataset with random values but same std and mean

plt.hist(sunflowers,
         range=(11, 15), histtype='step', linewidth=2,
        label='observed', normed=True)
plt.hist(sunflowers_normal,
         range=(11, 15), histtype='step', linewidth=2,
       label='normal', normed=True)
plt.legend()
plt.show()

# Calculate probabilities here:
experiments = np.random.binomial(200,0.1,5000) - binomial distribution where 200 sunflowers were planted and 10% probability of plants not blooming, 5000 samples
prob = np.mean(experiments<20)- probability that less than 20 flowers will fail to bloom
print prob - around 46%


%Bayes' Theorem


% Conditional Probability - P(event1) * P(event2) - where both events are independent
% The extra information about how we expect the world to work is called a prior.
% When we only use the first piece of information (the result of the test), 
  it's called a Frequentist Approach to statistics. When we incorporate our prior, it's called a Bayesian Approach.

P(A|B) = P(B|A)*P(A)/P(B) - Bayes'
P(B) = P(B|A)*P(A)+P(B|Anot)*P(Anot) - weighted average

import numpy as np
a = 'spam'
b = 'enhancement'
p_spam = 0.2
p_enhancement_given_spam = 0.05
p_enhancement = 0.05*0.2 + 0.001*0.8
print p_enhancement - 0.018
p_spam_enhancement = p_spam*p_enhancement_given_spam/p_enhancement
print p_spam_enhancement - 0.926
